2023-09-19 13:00:33,921 - root - INFO - Using device: cuda
2023-09-19 13:00:33,932 - root - INFO - GRID A100D-20C
2023-09-19 13:00:33,933 - root - INFO - Memory Usage:
2023-09-19 13:00:33,933 - root - INFO - Allocated: 0.0 GB
2023-09-19 13:00:33,933 - root - INFO - Cached: 0.0 GB
2023-09-19 13:00:34,022 - root - INFO - Preprocessing Internal_301_DB_layer3output dataset for train split.


100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63210/63210 [00:07<00:00, 8548.37it/s]
Augmenting dataset: 63210it [00:00, 2955486.94it/s]
2023-09-19 13:00:42,501 - root - INFO - Preprocessing Internal_301_DB_layer3output dataset for test split.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6622/6622 [00:00<00:00, 11162.18it/s]
2023-09-19 13:00:43,182 - root - INFO - Preprocessing Internal_301_DB_layer3output dataset for validation split.
0it [00:00, ?it/s]
2023-09-19 13:00:43,183 - root - INFO - Concatenating train set
2023-09-19 13:00:44,101 - root - INFO - Concatenating test set
2023-09-19 13:00:44,144 - root - INFO - Concatenating validation set
2023-09-19 13:00:45,736 - root - INFO - CustomModel(
  (stem): Resnet50(
    (stem): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=2048, out_features=1000, bias=True)
    )
  )
  (backbone): IsotropicBackBone(
    (backbone): Sequential(
      (0): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (4): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (5): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (6): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (7): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (8): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (9): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (10): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (11): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): MRConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
    )
  )
  (predictor): LinPredictor(
    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))
    (lin1): Linear(in_features=1024, out_features=301, bias=True)
    (act): GELU(approximate='none')
    (softmax): Softmax(dim=1)
  )
)
2023-09-19 13:00:45,743 - root - INFO - Using device: cuda
2023-09-19 13:00:45,743 - root - INFO - GRID A100D-20C
2023-09-19 13:00:45,743 - root - INFO - Memory Usage:
2023-09-19 13:00:45,744 - root - INFO - Allocated: 0.8 GB
2023-09-19 13:00:45,744 - root - INFO - Cached: 0.8 GB
Epoch 1 Training:   0%|                                                                                                                                         | 0/3951 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/ubuntu/finger-vein-quality-assessement/train.py", line 137, in <module>
    main()
  File "/home/ubuntu/finger-vein-quality-assessement/train.py", line 121, in main
    train(
  File "/home/ubuntu/finger-vein-quality-assessement/common/train_pipeline/train.py", line 177, in train
    outputs = model(inputs)  # pylint: disable=E1102
              ^^^^^^^^^^^^^
  File "/home/ubuntu/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/finger-vein-quality-assessement/common/train_pipeline/model/custom_model.py", line 38, in forward
    inputs = self.stem(inputs)
             ^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/finger-vein-quality-assessement/common/train_pipeline/stem/resnet50_l3.py", line 29, in forward
    inputs = self.stem.conv1(inputs)
             ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 463, in forward
    return self._conv_forward(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/nn/modules/conv.py", line 459, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
RuntimeError: Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 1024, 4, 8] to have 3 channels, but got 1024 channels instead