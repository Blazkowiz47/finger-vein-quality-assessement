2023-09-18 12:48:51,906 - root - INFO - Using device: cuda
2023-09-18 12:48:51,926 - root - INFO - Quadro M5000
2023-09-18 12:48:51,926 - root - INFO - Memory Usage:
2023-09-18 12:48:51,926 - root - INFO - Allocated: 0.0 GB
2023-09-18 12:48:51,927 - root - INFO - Cached: 0.0 GB
2023-09-18 12:48:52,112 - root - ERROR - Error reading validation dataset.
2023-09-18 12:48:52,112 - root - INFO - Preprocessing Internal_301_DB_layer3output dataset for train split.



















































































































































































































































































































































































































100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63210/63210 [13:30<00:00, 78.03it/s]
Augmenting dataset: 63210it [00:00, 1230447.01it/s]
2023-09-18 13:02:53,247 - root - INFO - Preprocessing Internal_301_DB_layer3output dataset for test split.


































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6622/6622 [01:09<00:00, 95.58it/s]
2023-09-18 13:04:04,236 - root - INFO - Preprocessing Internal_301_DB_layer3output dataset for validation split.
0it [00:00, ?it/s]
2023-09-18 13:04:04,256 - root - INFO - Concatenating train set
2023-09-18 13:04:23,780 - root - INFO - Concatenating test set
2023-09-18 13:04:27,715 - root - INFO - Concatenating validation set
2023-09-18 13:04:44,721 - root - INFO - CustomModel(
  (backbone): IsotropicBackBone(
    (backbone): Sequential(
      (0): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (4): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (5): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (6): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (7): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (8): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (9): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (10): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
2023-09-18 13:04:46,496 - root - INFO - Using device: cuda
2023-09-18 13:04:46,672 - root - INFO - Quadro M5000
2023-09-18 13:04:46,672 - root - INFO - Memory Usage:
2023-09-18 13:04:46,740 - root - INFO - Allocated: 2.7 GB
2023-09-18 13:04:46,740 - root - INFO - Cached: 2.7 GB
Epoch 1 Training:   0%|                                                                                                                                        | 0/7902 [00:00<?, ?it/s]/home/a-150/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,
Epoch 1 Training:   0%|                                                                                                                                        | 0/7902 [00:17<?, ?it/s]
Traceback (most recent call last):
  File "/home/a-150/work/finger-vein-quality-assessement/train.py", line 133, in <module>
    wandb.finish()
    ^^^^^^
  File "/home/a-150/work/finger-vein-quality-assessement/train.py", line 120, in main
    train(
  File "/home/a-150/work/finger-vein-quality-assessement/common/train_pipeline/train.py", line 179, in train
    loss.backward()
  File "/home/a-150/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/a-150/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.93 GiB (GPU 0; 7.93 GiB total capacity; 5.57 GiB already allocated; 1.85 GiB free; 5.59 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF