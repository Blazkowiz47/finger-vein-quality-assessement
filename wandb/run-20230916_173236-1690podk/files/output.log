2023-09-16 17:32:39,642 - root - INFO - Using device: cuda
2023-09-16 17:32:39,659 - root - INFO - Quadro M5000
2023-09-16 17:32:39,660 - root - INFO - Memory Usage:
2023-09-16 17:32:39,660 - root - INFO - Allocated: 0.0 GB
2023-09-16 17:32:39,660 - root - INFO - Cached: 0.0 GB
2023-09-16 17:32:39,734 - root - ERROR - Error reading validation dataset.
2023-09-16 17:32:39,734 - root - INFO - Preprocessing Internal_301_DB dataset for train split.



100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21070/21070 [00:07<00:00, 2674.43it/s]



Augmenting dataset: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 63210/63210 [00:07<00:00, 8045.14it/s]
2023-09-16 17:33:04,241 - root - INFO - Preprocessing Internal_301_DB dataset for test split.
100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6622/6622 [00:02<00:00, 3119.98it/s]
2023-09-16 17:33:07,204 - root - INFO - Preprocessing Internal_301_DB dataset for validation split.
0it [00:00, ?it/s]
2023-09-16 17:33:07,208 - root - INFO - Concatenating train set
2023-09-16 17:33:12,878 - root - INFO - Concatenating test set
2023-09-16 17:33:13,426 - root - INFO - Concatenating validation set
2023-09-16 17:33:15,581 - root - INFO - CustomModel(
  (stem): Resnet50(
    (stem): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (layer4): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (1): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): Bottleneck(
          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
      (fc): Linear(in_features=2048, out_features=1000, bias=True)
    )
  )
  (backbone): IsotropicBackBone(
    (backbone): Sequential(
      (0): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (1): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (2): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (3): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (4): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (5): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (6): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (7): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (8): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (9): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (10): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
      (11): Sequential(
        (0): Grapher(
          (fc1): Sequential(
            (0): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (graph_conv): DyGraphConv2d(
            (gconv): EdgeConv2d(
              (nn): BasicConv(
                (0): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), groups=4)
                (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
                (2): GELU(approximate='none')
              )
            )
            (dilated_knn_graph): DenseDilatedKnnGraph(
              (_dilated): DenseDilated()
            )
          )
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): AttentionBlock(
          (key): Linear(in_features=1024, out_features=1024, bias=True)
          (value): Linear(in_features=1024, out_features=1024, bias=True)
          (query): Linear(in_features=1024, out_features=1024, bias=True)
          (attention): MultiheadAttention(
            (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
          )
        )
        (2): FFN(
          (fc1): Sequential(
            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (act): GELU(approximate='none')
          (fc2): Sequential(
            (0): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1))
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
      )
    )
  )
  (predictor): LinPredictor(
    (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))
    (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1))
    (lin1): Linear(in_features=27648, out_features=2048, bias=True)
    (act): GELU(approximate='none')
    (lin2): Linear(in_features=2048, out_features=301, bias=True)
  )
)
2023-09-16 17:33:15,600 - root - INFO - Using device: cuda
2023-09-16 17:33:15,600 - root - INFO - Quadro M5000
2023-09-16 17:33:15,600 - root - INFO - Memory Usage:
2023-09-16 17:33:15,600 - root - INFO - Allocated: 1.1 GB
2023-09-16 17:33:15,601 - root - INFO - Cached: 1.1 GB
Epoch 1 Training:   0%|                                                                                                                                        | 0/6321 [00:00<?, ?it/s]/home/a-150/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/nn/modules/conv.py:459: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343995622/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)
  return F.conv2d(input, weight, bias, self.stride,


























































































Epoch 1 Training:   1%|█▊                                                                                                                           | 92/6321 [04:41<5:17:56,  3.06s/it]
Traceback (most recent call last):
  File "/home/a-150/work/finger-vein-quality-assessement/train.py", line 131, in <module>
    main()
  File "/home/a-150/work/finger-vein-quality-assessement/train.py", line 118, in main
    train(
  File "/home/a-150/work/finger-vein-quality-assessement/common/train_pipeline/train.py", line 179, in train
    loss.backward()
  File "/home/a-150/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/a-150/anaconda3/envs/dl-torch/lib/python3.11/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt